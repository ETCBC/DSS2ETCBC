{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbal stem and verbal tense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a comparison of the values of the features vs and vt in the dss, extrabiblical, and BHSA, dictionaries are made that are used to convert the values 1:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.fabric import Fabric\n",
    "\n",
    "TF = Fabric(locations='~/github/extrabiblical/tf/0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = TF.load('''\n",
    "    otype mother lex typ code sp book chapter verse label language\n",
    "''')\n",
    "\n",
    "api.loadLog()\n",
    "api.makeAvailableIn(globals())\n",
    "\n",
    "# Give classes a new name. This prevents that they will be overwritten\n",
    "Tx = T\n",
    "Lx = L\n",
    "Fx = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.app import use\n",
    "A = use('dss', hoist=globals())\n",
    "\n",
    "# give the relevant classes for the DSS new names\n",
    "Ldss = L\n",
    "Tdss = T\n",
    "Fdss = F\n",
    "Fall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf.app import use\n",
    "A = use('bhsa', hoist=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the values of the feature verbal stem of the BHSA and the dss package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSS\n",
    "\n",
    "LANG_DICT = {'g': 'Greek', 'a': 'Aramaic', None: 'Hebrew'}\n",
    "\n",
    "all_vs = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "\n",
    "for w in Fdss.otype.s('word'):\n",
    "    language = LANG_DICT[Fdss.lang.v(w)]\n",
    "    all_vs[language][Fdss.vs.v(w)] += 1\n",
    "    \n",
    "pprint(all_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrabiblical\n",
    "\n",
    "all_vs_x = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "\n",
    "for w in Fx.otype.s('word'):\n",
    "    language = Fx.language.v(w)\n",
    "    all_vs_x[language][F.vs.v(w)] += 1\n",
    "    \n",
    "pprint(all_vs_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BHSA\n",
    "\n",
    "all_vs_bhsa = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "    language = F.language.v(w)\n",
    "    all_vs_bhsa[language][F.vs.v(w)] += 1\n",
    "    \n",
    "pprint(all_vs_bhsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_dict_hebrew = {None: 'NA',\n",
    "                    'unknown': 'unknown',                  \n",
    "                    'hifil': 'hif',\n",
    "                    'hishtafel': 'hsht',\n",
    "                    'hitopel': 'hitopel',\n",
    "                    'hitpael': 'hit',\n",
    "                    'hitpalpel': 'hitpalpel',\n",
    "                    'hitpoel': 'htpo',\n",
    "                    'hofal': 'hof',\n",
    "                    'hotpaal': 'hotp',\n",
    "                    'hpealal': 'hpealal',\n",
    "                    'nifal': 'nif',\n",
    "                    'nitpael': 'nit',\n",
    "                    'palel': 'palel',\n",
    "                    'passive': 'pasq',\n",
    "                    'peal': 'peal',\n",
    "                    'piel': 'piel',\n",
    "                    'pilpel': 'pilpel',\n",
    "                    'poal': 'poal',\n",
    "                    'poel': 'poel',\n",
    "                    'polal': 'polal',\n",
    "                    'polel': 'polel',\n",
    "                    'pual': 'pual',\n",
    "                    'pulal': 'pulal',\n",
    "                    'qal': 'qal',\n",
    "                    'tifil': 'tif'}\n",
    "\n",
    "vs_dict_aramaic = {None: 'NA',\n",
    "                   'unknown': 'unknown',                  \n",
    "                   'aphel': 'afel',\n",
    "                   'apoel': 'apoel',\n",
    "                   'haphel': 'haf',\n",
    "                   'hishtaphel': 'hsht',\n",
    "                   'hithaphel': 'hithaphel',\n",
    "                   'hithpaal': 'htpa',\n",
    "                   'hithpeel': 'htpe',\n",
    "                   'hithpolel': 'hithpolel',\n",
    "                   'hophal': 'hof',\n",
    "                   'ishtaphel': 'ishtaphel',\n",
    "                   'ithpaal': 'ithpaal',\n",
    "                   'ithpeel': 'ithpeel',\n",
    "                   'ithpoel': 'ithpoel',\n",
    "                   'nifal': 'nif',\n",
    "                   'pael': 'pael',\n",
    "                   'peal': 'peal',\n",
    "                   'peil': 'peil',\n",
    "                   'poel': 'poel',\n",
    "                   'pual': 'pual',\n",
    "                   'pulal': 'pulal',\n",
    "                   'shaphel': 'shaf'}\n",
    "\n",
    "vs_dict_greek = {None: 'NA'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same with verbal tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSS\n",
    "\n",
    "all_vt = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "\n",
    "for w in Fdss.otype.s('word'):\n",
    "    language = LANG_DICT[Fdss.lang.v(w)]\n",
    "    all_vt[language][Fdss.vt.v(w)] += 1\n",
    "    \n",
    "pprint(all_vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrabiblical\n",
    "\n",
    "all_vt_x = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "\n",
    "for w in Fx.otype.s('word'):\n",
    "    language = Fx.language.v(w)\n",
    "    all_vt_x[language][F.vt.v(w)] += 1\n",
    "    \n",
    "pprint(all_vt_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BHSA\n",
    "\n",
    "all_vt_bhsa = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "    language = F.language.v(w)\n",
    "    all_vt_bhsa[language][F.vt.v(w)] += 1\n",
    "    \n",
    "pprint(all_vt_bhsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_dict_hebrew = {None: 'NA',\n",
    "                  'unknown': 'unknown',\n",
    "                  'impf': 'impf',\n",
    "                  'impv': 'impv',\n",
    "                  'infa': 'infa',\n",
    "                  'infc': 'infc',\n",
    "                  'perf': 'perf',\n",
    "                  'ptca': 'ptca',\n",
    "                  'ptcp': 'ptcp',\n",
    "                  'wayy': 'wayq'}\n",
    "\n",
    "vt_dict_aramaic = {None: 'NA',\n",
    "                   'unknown': 'unknown',\n",
    "                   'impf': 'impf',\n",
    "                   'impv': 'impv',\n",
    "                   'infc': 'infc',\n",
    "                   'perf': 'perf',\n",
    "                   'ptca': 'ptca',\n",
    "                   'ptcp': 'ptcp'}\n",
    "\n",
    "vt_dict_greek = {None: 'NA'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_nodes = []\n",
    "words = []\n",
    "vs_dss = []\n",
    "vs_etcbc = []\n",
    "vt_dss = []\n",
    "vt_etcbc = []\n",
    "\n",
    "for w in Fdss.otype.s('word'):\n",
    "    language= Fdss.lang.v(w)\n",
    "    tf_nodes.append(w)\n",
    "    words.append(Fdss.glyphe.v(w))\n",
    "    vs_dss.append(Fdss.vs.v(w))\n",
    "    vt_dss.append(Fdss.vt.v(w))\n",
    "    \n",
    "    if Fdss.lang.v(w) == 'a':    \n",
    "        vs_etcbc.append(vs_dict_aramaic[Fdss.vs.v(w)])\n",
    "        vt_etcbc.append(vt_dict_aramaic[Fdss.vt.v(w)])\n",
    "        \n",
    "    elif Fdss.lang.v(w) == 'g':\n",
    "        vs_etcbc.append(vs_dict_greek[Fdss.vs.v(w)])\n",
    "        vt_etcbc.append(vt_dict_greek[Fdss.vt.v(w)])\n",
    "        \n",
    "    else:\n",
    "        vs_etcbc.append(vs_dict_hebrew[Fdss.vs.v(w)])\n",
    "        vt_etcbc.append(vt_dict_hebrew[Fdss.vt.v(w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vs_vt = pd.DataFrame(list(zip(tf_nodes, words, vs_dss, vs_etcbc, vt_dss, vt_etcbc)), \n",
    "               columns =['tf_word_id', 'word', 'vs_dss','vs_etcbc','vt_dss','vt_etcbc']) \n",
    "\n",
    "df_vs_vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vs_vt.to_csv(\"vs_vt_all_scrolls.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
